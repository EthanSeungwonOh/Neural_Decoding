{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-decoding-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkGiVYSfPp0PF52oCncq5w"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-1e2CLC7o-S",
        "colab_type": "text"
      },
      "source": [
        "# ML Experiment Tips!\n",
        "- If your model is underfitting the training data, adding more training examples will not help. You need to use a more complex model or come up with better features.\n",
        "\n",
        "- One way to improve an overfitting model is to feed it more training data until the validation error reaches the training error.\n",
        "\n",
        "- Bias-Variance Tradeoff: Increasing a model’s complexity will typically increase its variance and reduce its bias. Conversely, reducing a model’s complexity increases its bias and reduces its variance. This is why it is called a trade-off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPsrZtvFe2bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Neural-Decoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPzPUWix1I_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfb9387b-8d0f-4f16-fc4a-024431dc6ce1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import loadtxt\n",
        "\n",
        "# Binary Classification with Sonar Dataset: Baseline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PK-WBnauY07",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ace8bdd5-d984-40b5-9e28-9b08731f6055"
      },
      "source": [
        "# load the dataset\n",
        "path = '/content/drive/My Drive/data/data_lda_20170828/1004'\n",
        "\n",
        "data_list = [(3,1),(3,2),(4,1),(4,2),(4,3),(5,3)] \n",
        "data_list2 = [(1,4),(1,5),(1,6),(2,1),(2,2),(2,6),(3,1),(3,2),(4,1),(4,2),(4,3),(5,2),(5,3)] \n",
        "k = len(data_list2)\n",
        "\n",
        "# list of dictionary : a form of day and inj\n",
        "cellMouse = path.split('/')[-1]\n",
        "\n",
        "# dirs = glob.glob(os.path.join(path, '1*'))\n",
        "X_list = []\n",
        "Y_list = []\n",
        "\n",
        "# for each video folder\n",
        "for day, inj in data_list2:\n",
        "  datasetName = os.path.join(path, 'TRACES_'+ cellMouse +'_'+ str(day) +'_' + str(inj) +'.csv')\n",
        "  labelName = os.path.join(path, 'BEHAVIOR_'+ cellMouse +'_'+ str(day) +'_' +str(inj)+'.csv')\n",
        "\n",
        "  dataset = np.transpose(loadtxt(datasetName, delimiter=','))\n",
        "  label = loadtxt(labelName, delimiter=',')[:,2]\n",
        "\n",
        "  X_list.append(dataset)\n",
        "  Y_list.append(label)\n",
        "\n",
        "X = np.vstack(X_list)\n",
        "y = np.vstack(Y_list)\n",
        "y = y.reshape(-1)\n",
        "\n",
        "scaler = StandardScaler() # expected dim=2\n",
        "X = scaler.fit_transform(X) # normalize/standardize features\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39000, 273) (39000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtNzq9fGmZv",
        "colab_type": "text"
      },
      "source": [
        "## Feature Preprecessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc_yKHpNL3G7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb77e086-0503-49f3-b7e3-d479c43c6e23"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39000, 273)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCxiVkZELNQ0",
        "colab_type": "text"
      },
      "source": [
        "## Non-Recurrent Decoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQZby7Bb_uAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c0c880e-a8d0-46e1-9719-c8f5c1ebae36"
      },
      "source": [
        "# X: (3000*# of videos, num_features) -> select bin_len -> (3000*# of videos/bin_len, bin_len, num_features) \n",
        "# -> select B_num -> (3000*# of videos/(bin_len*bin_num), bin_len * bin_num * num_features) \n",
        "\n",
        "# y: (3000*# of videos, 1) -> (3000*# of videos/(bin_len*bin_num), 600) -> leave the last output in aggregated B bins -> (3000*# of videos/(bin_len*bin_num), 1)\n",
        "\n",
        "bin_len = 10 # = temporal resolution R \n",
        "bin_num = 1 # number of bins for a prediction B\n",
        "num_features = 273 # number of features N\n",
        "\n",
        "X = X.reshape(-1, bin_len*bin_num*num_features)\n",
        "y = y.reshape(-1, bin_len*bin_num)\n",
        "y = y[:,-1]\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3900, 2730) (3900,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDb2MPF3wJ53",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I48UI6CwMBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_estimators=\n",
        "max_features=\n",
        "max_depth=\n",
        "min_samples_split=\n",
        "min_samples_leaf="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFCTn9OBLWEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_RF(X_train, y_train, X_test):\n",
        "  rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "  rnd_clf.fit(X_train, y_train)\n",
        "  y_pred = rnd_clf.predict(X_test)\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t37AC737L37J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_SVM(X_train, y_train, X_test): # use the SVC class with a linear kernel.\n",
        "  # scales the features \n",
        "  svm_clf = Pipeline([\n",
        "          (\"scaler\", StandardScaler()),\n",
        "          (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
        "      ])\n",
        "  svm_clf.fit(X_train, y_train)\n",
        "  # Unlike Logistic Regression classifiers, SVM classifiers do not output probabilities for each class\n",
        "  y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0IKPNHCKuES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "49f4f41b-82ed-48ef-b61e-36c4e0b8321a"
      },
      "source": [
        "# train using cross-validation\n",
        "num_val_samples = len(X) // k\n",
        "print(num_val_samples)\n",
        "\n",
        "all_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "    print('processing fold #', i+1)\n",
        "    val_X = X[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "    val_y = y[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "\n",
        "    train_X = np.concatenate(                                     \n",
        "        [X[:i * num_val_samples],\n",
        "         X[(i + 1) * num_val_samples:]], axis=0)\n",
        "\n",
        "    train_y = np.concatenate(\n",
        "        [y[:i * num_val_samples],\n",
        "         y[(i + 1) * num_val_samples:]], axis=0)\n",
        "  \n",
        "    y_pred = build_SVM(train_X, train_y, val_X)\n",
        "    all_scores.append(accuracy_score(val_y, y_pred))\n",
        "\n",
        "print(all_scores)\n",
        "print(\"average accuracy: {} \".format(np.mean(all_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n",
            "processing fold # 4\n",
            "processing fold # 5\n",
            "processing fold # 6\n",
            "processing fold # 7\n",
            "processing fold # 8\n",
            "processing fold # 9\n",
            "processing fold # 10\n",
            "processing fold # 11\n",
            "processing fold # 12\n",
            "processing fold # 13\n",
            "[0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.8, 0.8, 0.6, 1.0, 0.4]\n",
            "average accuracy: 0.7230769230769231 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cjto6TmKmuo",
        "colab_type": "text"
      },
      "source": [
        "## DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PWnBEmRAzXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6488f00b-6cda-4461-fd9e-a48e0f57f48f"
      },
      "source": [
        "def build_dnn(bin_len, bin_num, num_features):\n",
        "    model = keras.Sequential(\n",
        "  [\n",
        "   layers.Dense(40, input_shape=(bin_len*bin_num*num_features,)),\n",
        "   layers.Dropout(0.2),\n",
        "   layers.Dense(20, activation='relu'),\n",
        "   layers.Dropout(0.2),\n",
        "   layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.01) \n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_dnn(bin_len, bin_num, num_features)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_101 (Dense)            (None, 40)                109240    \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 110,081\n",
            "Trainable params: 110,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYSvKCvuEKF9",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Decoders: LSTM/GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ-3RXi2cKrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42fa5595-524a-4506-ffef-9b3322711171"
      },
      "source": [
        "# Recurrent Neural Decoders: LSTM/GRU\n",
        "# 1. decide the temporal resolution, R\n",
        "# T/R total data points\n",
        "\n",
        "# 2. decide the time period to predict a given output (output data must be further preprocessed)\n",
        "# a. every timestep in a bin (no preprocessing y required)\n",
        "# b. last timestep in a bin\n",
        "# c. last timestep in multiple bins\n",
        "\n",
        "# X: (3000*# of videos, num_features) -> select bin_len -> (3000*# of videos/bin_len, bin_len, num_features) \n",
        "# -> select B_num -> (3000*# of videos/(bin_len*bin_num), bin_len*bin_num * num_features) \n",
        "\n",
        "# y: (3000*# of videos, 1) -> (3000*# of videos/(bin_len*bin_num), 600) -> leave the last output in aggregated B bins -> (3000*# of videos/(bin_len*bin_num), 1)\n",
        "\n",
        "bin_len = 200 # = temporal resolution R (window)\n",
        "bin_num = 3 # number of bins for a prediction B\n",
        "num_features = 273 # number of features N\n",
        "\n",
        "X = X.reshape(-1, bin_len*bin_num, num_features) \n",
        "y = y.reshape(-1, bin_len*bin_num, 1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(65, 600, 273) (65, 600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYr2RjEqsWto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2411d689-ea4c-4c6f-99b9-c95a17ad4f46"
      },
      "source": [
        "def build_lstm(bin_len, bin_num, num_features):\n",
        "    model = keras.Sequential(\n",
        "  [\n",
        "   layers.LSTM(units=100, input_shape=(bin_len*bin_num, num_features), return_sequences=True),\n",
        "   layers.Dropout(0.2),\n",
        "   layers.TimeDistributed(layers.Dense(1, activation='sigmoid'))\n",
        "  ])\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.01) \n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_lstm(bin_len, bin_num, num_features)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_15 (LSTM)               (None, 600, 100)          149600    \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 600, 100)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 600, 1)            101       \n",
            "=================================================================\n",
            "Total params: 149,701\n",
            "Trainable params: 149,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7xz9naEOdy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c2b666a-0fdc-4511-bb69-b8219c7fc2ad"
      },
      "source": [
        "# train using cross-validation\n",
        "num_val_samples = len(X) // k\n",
        "print(num_val_samples)\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 20 # of batches = (# of examples / batch_size)\n",
        "\n",
        "all_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "    print('processing fold #', i+1)\n",
        "    val_X = X[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "    val_y = y[i * num_val_samples : (i + 1) * num_val_samples]\n",
        "\n",
        "    train_X = np.concatenate(                                     \n",
        "        [X[:i * num_val_samples],\n",
        "         X[(i + 1) * num_val_samples:]], axis=0)\n",
        "\n",
        "    train_y = np.concatenate(\n",
        "        [y[:i * num_val_samples],\n",
        "         y[(i + 1) * num_val_samples:]], axis=0)\n",
        "  \n",
        "    model = build_lstm(bin_len, bin_num, num_features)                                 \n",
        "    history = model.fit(train_X, train_y, epochs=num_epochs, batch_size=batch_size, validation_data=(val_X, val_y), verbose=1)\n",
        "    val_loss, val_acc = model.evaluate(val_X, val_y, verbose=0)      \n",
        "    all_scores.append(val_acc)\n",
        "\n",
        "print(all_scores)\n",
        "print(\"average accuracy: {} \".format(np.mean(all_scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "processing fold # 1\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 170ms/step - loss: 0.7273 - accuracy: 0.5873 - val_loss: 0.7603 - val_accuracy: 0.5577\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5701 - accuracy: 0.7089 - val_loss: 0.7448 - val_accuracy: 0.5480\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5103 - accuracy: 0.7562 - val_loss: 0.7505 - val_accuracy: 0.5337\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4710 - accuracy: 0.7842 - val_loss: 0.7580 - val_accuracy: 0.5470\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4242 - accuracy: 0.8154 - val_loss: 0.7966 - val_accuracy: 0.5387\n",
            "processing fold # 2\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.7400 - accuracy: 0.5789 - val_loss: 0.6148 - val_accuracy: 0.6450\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.5716 - accuracy: 0.7040 - val_loss: 0.6404 - val_accuracy: 0.5970\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5212 - accuracy: 0.7481 - val_loss: 0.6755 - val_accuracy: 0.5557\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.4839 - accuracy: 0.7820 - val_loss: 0.6337 - val_accuracy: 0.6073\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.4387 - accuracy: 0.8089 - val_loss: 0.6105 - val_accuracy: 0.6663\n",
            "processing fold # 3\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 0.7224 - accuracy: 0.5903 - val_loss: 0.6916 - val_accuracy: 0.6493\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.5737 - accuracy: 0.6921 - val_loss: 0.6164 - val_accuracy: 0.6690\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5182 - accuracy: 0.7491 - val_loss: 0.6057 - val_accuracy: 0.6727\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4700 - accuracy: 0.7876 - val_loss: 0.6349 - val_accuracy: 0.6680\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.4180 - accuracy: 0.8196 - val_loss: 0.6255 - val_accuracy: 0.6733\n",
            "processing fold # 4\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 150ms/step - loss: 0.7728 - accuracy: 0.5601 - val_loss: 0.5289 - val_accuracy: 0.6867\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.5811 - accuracy: 0.6982 - val_loss: 0.5677 - val_accuracy: 0.7193\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5317 - accuracy: 0.7511 - val_loss: 0.5375 - val_accuracy: 0.7153\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4855 - accuracy: 0.7823 - val_loss: 0.5130 - val_accuracy: 0.7217\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4393 - accuracy: 0.8118 - val_loss: 0.5237 - val_accuracy: 0.7317\n",
            "processing fold # 5\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.7852 - accuracy: 0.5628 - val_loss: 0.5332 - val_accuracy: 0.7327\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.5954 - accuracy: 0.6926 - val_loss: 0.6139 - val_accuracy: 0.6747\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.5409 - accuracy: 0.7448 - val_loss: 0.6222 - val_accuracy: 0.6407\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4996 - accuracy: 0.7682 - val_loss: 0.5741 - val_accuracy: 0.6907\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.4595 - accuracy: 0.7961 - val_loss: 0.5738 - val_accuracy: 0.6843\n",
            "processing fold # 6\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 0.7593 - accuracy: 0.5809 - val_loss: 0.6856 - val_accuracy: 0.5983\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5803 - accuracy: 0.6977 - val_loss: 0.7112 - val_accuracy: 0.5390\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5220 - accuracy: 0.7548 - val_loss: 0.6861 - val_accuracy: 0.6027\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4784 - accuracy: 0.7811 - val_loss: 0.6998 - val_accuracy: 0.5810\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4375 - accuracy: 0.8057 - val_loss: 0.7800 - val_accuracy: 0.5187\n",
            "processing fold # 7\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 0.7538 - accuracy: 0.5794 - val_loss: 0.7686 - val_accuracy: 0.5737\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5722 - accuracy: 0.6868 - val_loss: 0.7065 - val_accuracy: 0.5783\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5202 - accuracy: 0.7517 - val_loss: 0.7099 - val_accuracy: 0.5940\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4785 - accuracy: 0.7792 - val_loss: 0.7240 - val_accuracy: 0.5957\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4311 - accuracy: 0.8134 - val_loss: 0.7436 - val_accuracy: 0.5867\n",
            "processing fold # 8\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 0.7076 - accuracy: 0.5804 - val_loss: 0.7178 - val_accuracy: 0.5627\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5499 - accuracy: 0.7214 - val_loss: 0.7084 - val_accuracy: 0.5557\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4942 - accuracy: 0.7633 - val_loss: 0.7557 - val_accuracy: 0.5513\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4498 - accuracy: 0.7987 - val_loss: 0.7818 - val_accuracy: 0.5607\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3981 - accuracy: 0.8270 - val_loss: 0.8017 - val_accuracy: 0.5750\n",
            "processing fold # 9\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 0.7518 - accuracy: 0.5965 - val_loss: 0.6827 - val_accuracy: 0.5937\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.5975 - accuracy: 0.6664 - val_loss: 0.6540 - val_accuracy: 0.6157\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.5440 - accuracy: 0.7317 - val_loss: 0.6633 - val_accuracy: 0.6007\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.5102 - accuracy: 0.7523 - val_loss: 0.6874 - val_accuracy: 0.5957\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4679 - accuracy: 0.7898 - val_loss: 0.6796 - val_accuracy: 0.6153\n",
            "processing fold # 10\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 157ms/step - loss: 0.7272 - accuracy: 0.5688 - val_loss: 0.6747 - val_accuracy: 0.6427\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.5650 - accuracy: 0.7103 - val_loss: 0.6277 - val_accuracy: 0.6390\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5114 - accuracy: 0.7636 - val_loss: 0.6291 - val_accuracy: 0.6450\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.4554 - accuracy: 0.7961 - val_loss: 0.6495 - val_accuracy: 0.6397\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4054 - accuracy: 0.8259 - val_loss: 0.6603 - val_accuracy: 0.6317\n",
            "processing fold # 11\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 0.6878 - accuracy: 0.5892 - val_loss: 0.6394 - val_accuracy: 0.6523\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.5390 - accuracy: 0.7324 - val_loss: 0.5940 - val_accuracy: 0.6833\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4860 - accuracy: 0.7650 - val_loss: 0.6030 - val_accuracy: 0.6743\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4299 - accuracy: 0.8082 - val_loss: 0.5987 - val_accuracy: 0.6893\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3722 - accuracy: 0.8429 - val_loss: 0.6097 - val_accuracy: 0.6867\n",
            "processing fold # 12\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 0.7581 - accuracy: 0.5576 - val_loss: 0.5092 - val_accuracy: 0.7603\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6123 - accuracy: 0.6643 - val_loss: 0.5790 - val_accuracy: 0.7347\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5514 - accuracy: 0.7278 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.5169 - accuracy: 0.7565 - val_loss: 0.4696 - val_accuracy: 0.7890\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4740 - accuracy: 0.7854 - val_loss: 0.4826 - val_accuracy: 0.7897\n",
            "processing fold # 13\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 1s 171ms/step - loss: 0.7726 - accuracy: 0.5772 - val_loss: 0.7062 - val_accuracy: 0.5963\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5820 - accuracy: 0.7014 - val_loss: 0.6538 - val_accuracy: 0.6167\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5194 - accuracy: 0.7529 - val_loss: 0.6382 - val_accuracy: 0.6163\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4838 - accuracy: 0.7790 - val_loss: 0.6437 - val_accuracy: 0.6120\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.4380 - accuracy: 0.8124 - val_loss: 0.6553 - val_accuracy: 0.6193\n",
            "[0.5386666655540466, 0.6663333177566528, 0.6733333468437195, 0.7316666841506958, 0.684333324432373, 0.518666684627533, 0.5866666436195374, 0.574999988079071, 0.6153333187103271, 0.6316666603088379, 0.6866666674613953, 0.7896666526794434, 0.6193333268165588]\n",
            "average accuracy: 0.6397948677723224 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x5RY-YSIHiT",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Train/Val Loss/Acc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA6y3v52Vtib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b4a06c2c-8512-4e4d-f330-05bc9ae05977"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbxoayK47eID",
        "colab_type": "text"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExjvLpH1IXBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='hard')\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii-PCTv0I4D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRtOnc1uuMWr",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhkvUvR8RZG",
        "colab_type": "text"
      },
      "source": [
        "### Linear SVM Classification\n",
        "If two classes can clearly be linearly separated easily with a straight line (decision boundary), we start with using LinearSVM.\n",
        "\n",
        "However, if the decision boundaries come so close to the instances, then these models will probably not perform well on new instances.\n",
        "\n",
        "Therefore, we aim to not only separate the two classes but also stays as far away from the closest training instances as possible (think SVM of fitting the widest possible street between the classification : large margin classification)\n",
        "\n",
        "decision boundary is full determined by the instances located on the edge of the street and such instances are called **\"SUPPORT VECTORS\"**\n",
        "```\n",
        "- SVMs are sensitive to the feature scales, be sure to use StandardScaler for feature scaling\n",
        "- If your SVM model is overfitting, try regularizing it by reducing C\n",
        "```\n",
        "\n",
        "### Soft vs. Hard margin classification\n",
        "all instance must be off the street and on the right side, this is called hard margin. There are two main issues with it that it only works when the data is linearly separable and sensitive to outliars.\n",
        "\n",
        "To avoid these issues, use a more flexible model called soft margin. The objective is to find a good balance between maximizing the margin and limiting the margin violations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwqpj-qb6rV1",
        "colab_type": "text"
      },
      "source": [
        "Instead of using the LinearSVC class, we could use the SVC class with a linear kernel. When creating the SVC model, we would write SVC(kernel=\"linear\", C=1).\n",
        "\n",
        "```\n",
        "The LinearSVC class regularizes the bias term, so you should center the training set first by subtracting its mean. This is automatic if you scale the data using the StandardScaler. Also make sure you set the loss hyperparameter to \"hinge\", as it is not the default value. Finally, for better performance, you should set the dual hyperparameter to False, unless there are more features than training instances.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l5fyXtr51fM",
        "colab_type": "text"
      },
      "source": [
        "## Nonlinear SVM Classification\n",
        "\n",
        "many datasets are not even close to being linearly separable.\n",
        "\n",
        "One approach is to add more features (polynomial features) and in somes cases it results in linearly separable dataset.\n",
        "\n",
        "Although it is simple to implement, it poses issues that at a low degree it cannot deal with complex dataset and with a high degree it creates a huge number of features, making the training too slow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMlMawmIFuFN",
        "colab_type": "text"
      },
      "source": [
        "### kernel trick\n",
        "makes it possible to get the same results as if you had added many polynomial features, even with very high-degree polynomials, without actually having to add them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hR5Qdejw9MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Polynomial Kernel\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "poly_kernel_svm_clf = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        "    ])\n",
        "\n",
        "poly_kernel_svm_clf.fit(X_train, y_train)\n",
        "y_pred = poly_kernel_svm_predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0oFvWOE4_Th",
        "colab_type": "text"
      },
      "source": [
        "**With so many kernels to choose from, how can you decide which one to use?**\n",
        "```\n",
        "As a rule of thumb, you should always try the linear kernel first (remember that LinearSVC is much faster than SVC(kernel=\"linear\")), especially if the training set is very large or if it has plenty of features. If the training set is not too large, you should also try the Gaussian RBF kernel; it works well in most cases. Use cross-validation and grid search for searching a few other kernels. You’d want to experiment like that especially if there are kernels specialized for your training set’s data structure.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57koRIML7lhY",
        "colab_type": "text"
      },
      "source": [
        "For online learning, we could use the SGDClassifier class, with SGDClassifier(loss=\"hinge\", alpha=1/(m*C)). This applies regular Stochastic Gradient Descent to train a linear SVM classifier. It does not converge as fast as the LinearSVC class, but it can be useful to handle online classification tasks or huge datasets that do not fit in memory (out-of-core training)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAonYsGg0sLj",
        "colab_type": "text"
      },
      "source": [
        "### Under the Hood\n",
        "The linear SVM classifier model predicts the class of a new instance x by simply computing the decision function w⊺ x + b = w1 x1 + ⋯ + wn xn + b. If the result is positive, the predicted class ŷ is the positive class (1), and otherwise it is the negative class (0)\n",
        "\n",
        "\n",
        "Consider the slope of the decision function: it is equal to the norm of the weight vector, ∥ w ∥. If we divide this slope by 2, the points where the decision function is equal to ±1 are going to be twice as far away from the decision boundary. \n",
        "\n",
        "```\n",
        "dividing the slope by 2 will multiply the margin by 2. The smaller the weight vector w, the larger the margin.\n",
        "```\n",
        "\n",
        "Training a linear SVM classifier means finding the values of w and b that make this margin as wide as possible while avoiding margin violations (hard margin) or limiting them (soft margin)."
      ]
    }
  ]
}